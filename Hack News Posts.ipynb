{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Writing Posts that Receive the Most Attention: Exploring 'Hacker News' Posts\n",
    "\n",
    "Many people have had instances where they are faced with questions requiring urgent attention/answers. For some, they are only eager to share their experiences and let people learn from them. The people in these two circumstances all want other users on that platform, not just to see their posts (questions or stories), but to also react. The reaction to such posts can either be by liking or (most especially for questions) by commenting. Unfortunately, many posters' expectations are not met as their posts may goes for weeks without receiving any reaction. This issue is mostly faced by the newest members of a platform as well as some old members. These individuals (especially learners) requiring urgent attentions to some problems become frustrated and discouraged. Therefore, the understanding of a platform and the activity of its users - most especially the understanding of what type of posts to write and when to write them - is paramount to receiving engagement/attention for a post.\n",
    "\n",
    "In this project, we want to examine and analyze data set of submissions to popular technology site [Hacker News](https://news.ycombinator.com/) which was started by [Y Combinator](https://www.ycombinator.com/). A portion of this [data set](https://www.kaggle.com/hacker-news/hacker-news-posts) (approximately 20,000 rows) will be used for this analysis. The whole [data set](https://www.kaggle.com/hacker-news/hacker-news-posts) was streamlined by removing all submissions that did not receive any comments, and the remaining submissions was randomly sampled.\n",
    "\n",
    "Posts on [Hacker News](https://news.ycombinator.com/) are usually taggged at the beginning with some keywords. In this analysis, our interest is focused on posts whose titles begin with either *Ask HN* or *Show HN*. These two tags represent posts that users submit to ask the Hacker News community a specific question and posts that are used to show the community what a user is up to respectively. We'll compare those two types of posts with the goal of determining whether:\n",
    "\n",
    "   * Either types of post receive more comments on average\n",
    "   * Posts created at a certain time receive more comments on average\n",
    "   \n",
    "_______\n",
    "\n",
    "**Results**\n",
    "\n",
    "In this analysis, it was found that:\n",
    "\n",
    "   1. Question posts (i.e. Post with 'Ask HN' tag) have a higher average number of comments compared to Show Posts.\n",
    "   2. Posts that are sent within the hours of 15:00 EDT (8PM Nigerian time), receive the most engagement (comments)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Importing the Hacker News data set\n",
    "from csv import reader\n",
    "opened_file = open('hacker_news.csv', encoding=\"Latin-1\")\n",
    "read_file = reader(opened_file)\n",
    "hn = list(read_file) # the data set's list of list\n",
    "\n",
    "hn_header = hn[0] # Header row\n",
    "hn = hn[1:] # Rows containing the submissions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is a function to view the shape of our data set. We display the header row and the first ten rows of our data set in order to get a grasp of how our data look and what the data set is all about. As we'll see below, the first list in the inner lists contains the column headers, and the lists after contain the data for other rows. Below are descriptions of the column headers:\n",
    "\n",
    "  * id: The unique identifier from Hacker News for the post\n",
    "  * title: The title of the post\n",
    "  * url: The URL that the posts links to, if it the post has a URL\n",
    "  * num_points: The number of points the post acquired, calculated as the total number of upvotes minus the total number of downvotes\n",
    "  * num_comments: The number of comments that were made on the post\n",
    "  * author: The username of the person who submitted the post\n",
    "  * created_at: The date and time at which the post was submitted\n",
    "  * In order to work with and analyze our data, we first need to remove the first row (which contains the column headers) from the other rows containing the data for the submissions. Below, the data is assigned to hn and column header is isolated to a separate variable headers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['id', 'title', 'url', 'num_points', 'num_comments', 'author', 'created_at']\n",
      "\n",
      "\n",
      "['12224879', 'Interactive Dynamic Video', 'http://www.interactivedynamicvideo.com/', '386', '52', 'ne0phyte', '8/4/2016 11:52']\n",
      "\n",
      "\n",
      "['10975351', 'How to Use Open Source and Shut the Fuck Up at the Same Time', 'http://hueniverse.com/2016/01/26/how-to-use-open-source-and-shut-the-fuck-up-at-the-same-time/', '39', '10', 'josep2', '1/26/2016 19:30']\n",
      "\n",
      "\n",
      "['11964716', \"Florida DJs May Face Felony for April Fools' Water Joke\", 'http://www.thewire.com/entertainment/2013/04/florida-djs-april-fools-water-joke/63798/', '2', '1', 'vezycash', '6/23/2016 22:20']\n",
      "\n",
      "\n",
      "['11919867', 'Technology ventures: From Idea to Enterprise', 'https://www.amazon.com/Technology-Ventures-Enterprise-Thomas-Byers/dp/0073523429', '3', '1', 'hswarna', '6/17/2016 0:01']\n",
      "\n",
      "\n",
      "['10301696', 'Note by Note: The Making of Steinway L1037 (2007)', 'http://www.nytimes.com/2007/11/07/movies/07stein.html?_r=0', '8', '2', 'walterbell', '9/30/2015 4:12']\n",
      "\n",
      "\n",
      "['10482257', 'Title II kills investment? Comcast and other ISPs are now spending more', 'http://arstechnica.com/business/2015/10/comcast-and-other-isps-boost-network-investment-despite-net-neutrality/', '53', '22', 'Deinos', '10/31/2015 9:48']\n",
      "\n",
      "\n",
      "['10557283', 'Nuts and Bolts Business Advice', '', '3', '4', 'shomberj', '11/13/2015 0:45']\n",
      "\n",
      "\n",
      "['12296411', 'Ask HN: How to improve my personal website?', '', '2', '6', 'ahmedbaracat', '8/16/2016 9:55']\n",
      "\n",
      "\n",
      "['11337617', 'Shims, Jigs and Other Woodworking Concepts to Conquer Technical Debt', 'http://firstround.com/review/shims-jigs-and-other-woodworking-concepts-to-conquer-technical-debt/', '34', '7', 'zt', '3/22/2016 16:18']\n",
      "\n",
      "\n",
      "['10379326', 'That self-appendectomy', 'http://www.southpolestation.com/trivia/igy1/appendix.html', '91', '10', 'jimsojim', '10/13/2015 9:30']\n",
      "\n",
      "\n",
      "Number of rows: 20100\n",
      "Number of columns: 7\n"
     ]
    }
   ],
   "source": [
    "# a function to view the state of the data set\n",
    "\n",
    "def explore_data(dataset, start, end, rows_and_columns=False):\n",
    "    dataset_slice = dataset[start:end]\n",
    "    for row in dataset_slice:\n",
    "        print(row)\n",
    "        print('\\n')\n",
    "        \n",
    "    if rows_and_columns:\n",
    "        print('Number of rows:', len(dataset))\n",
    "        print('Number of columns:', len(dataset[0]))\n",
    "        \n",
    "print(hn_header)\n",
    "print('\\n')\n",
    "explore_data(hn, 0, 10, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As seen above, some of the submissions do not include the specific tags (Ask Posts ans Show Posts). Since our focus is on those posts whose titles begin with either *Ask HN* or *Show HN*, we'll create a new list of lists containing just the data for those titles with tags. We'll create separate lists for Ask HN and Show HN posts as well as include others with no tags in a list called `other_post`. The tags are usually included with the titles. Although some of these titles include the tags, when the data set is observed carefully it was noticed that the cases are different from post to post. Some begin with or have the tags all written in uppercase letters while others are in lowercase. We'll therefore make a provision to accomodate all these rows appropriately.\n",
    "\n",
    "Afterwards, we'll check the length (i.e. the number of rows) of each list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1744\n",
      "1162\n",
      "17194\n"
     ]
    }
   ],
   "source": [
    "ask_posts = []\n",
    "show_posts = []\n",
    "other_posts = []\n",
    "\n",
    "for row in hn:       # iterating over each row of the lists\n",
    "    title = row[1]   # we specify the second column of each row as title\n",
    "    if title.lower().startswith('ask hn'):  # we convert the titles to lowercase to accomodate every letter case\n",
    "        ask_posts.append(row)\n",
    "    elif title.lower().startswith('show hn'):\n",
    "        show_posts.append(row)\n",
    "    else:\n",
    "        other_posts.append(row)\n",
    "        \n",
    "print(len(ask_posts))\n",
    "print(len(show_posts))\n",
    "print(len(other_posts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So now we have separated the different types of posts we have in our data set. We have 1,744 rows of Ask posts, 1,162 rows of Show posts and 17,194 rows for others.\n",
    "\n",
    "Next we'll view the first five rows for each of Ask and Show posts. This is just to see whether we have done the right thing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['12296411', 'Ask HN: How to improve my personal website?', '', '2', '6', 'ahmedbaracat', '8/16/2016 9:55'], ['10610020', 'Ask HN: Am I the only one outraged by Twitter shutting down share counts?', '', '28', '29', 'tkfx', '11/22/2015 13:43'], ['11610310', 'Ask HN: Aby recent changes to CSS that broke mobile?', '', '1', '1', 'polskibus', '5/2/2016 10:14'], ['12210105', 'Ask HN: Looking for Employee #3 How do I do it?', '', '1', '3', 'sph130', '8/2/2016 14:20'], ['10394168', 'Ask HN: Someone offered to buy my browser extension from me. What now?', '', '28', '17', 'roykolak', '10/15/2015 16:38']]\n",
      "\n",
      "\n",
      "[['10627194', 'Show HN: Wio Link  ESP8266 Based Web of Things Hardware Development Platform', 'https://iot.seeed.cc', '26', '22', 'kfihihc', '11/25/2015 14:03'], ['10646440', 'Show HN: Something pointless I made', 'http://dn.ht/picklecat/', '747', '102', 'dhotson', '11/29/2015 22:46'], ['11590768', 'Show HN: Shanhu.io, a programming playground powered by e8vm', 'https://shanhu.io', '1', '1', 'h8liu', '4/28/2016 18:05'], ['12178806', 'Show HN: Webscope  Easy way for web developers to communicate with Clients', 'http://webscopeapp.com', '3', '3', 'fastbrick', '7/28/2016 7:11'], ['10872799', 'Show HN: GeoScreenshot  Easily test Geo-IP based web pages', 'https://www.geoscreenshot.com/', '1', '9', 'kpsychwave', '1/9/2016 20:45']]\n"
     ]
    }
   ],
   "source": [
    "print(ask_posts[:5])\n",
    "print('\\n')\n",
    "print(show_posts[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Average Number of Comments Received by Ask Posts and Show Posts\n",
    "\n",
    "All seems great so far!\n",
    "\n",
    "Right now, we'll calculate the average number of comments received by all posts in Ask post category and also the Show post category. We want to perform this action in order to fulfill one of the goals of this project and to also determine the category to analyze further."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average number of comments received by ask posts is \n",
      "14.038417431192661\n",
      "\n",
      "\n",
      "The average number of comments received by show post is \n",
      "10.31669535283993\n"
     ]
    }
   ],
   "source": [
    "total_ask_comments = 0\n",
    "\n",
    "for posts in ask_posts:\n",
    "    num_comments = posts[4]\n",
    "    num_comments = int(num_comments)\n",
    "    \n",
    "    # adding each number of comments to the total comments variable\n",
    "    total_ask_comments += num_comments\n",
    "\n",
    "\n",
    "avg_ask_comments = total_ask_comments / len(ask_posts)\n",
    "print('The average number of comments received by ask posts is \\n' + str(\n",
    "    avg_ask_comments))\n",
    "print('\\n')\n",
    "\n",
    "\n",
    "total_show_comments = 0\n",
    "\n",
    "for posts in show_posts:\n",
    "    num_comments = posts[4]\n",
    "    num_comments = int(num_comments)\n",
    "    \n",
    "    # adding each number of comments to the total comments variable\n",
    "    total_show_comments += num_comments\n",
    "    \n",
    "    \n",
    "avg_show_comments = total_show_comments / len(\n",
    "    show_posts)\n",
    "print('The average number of comments received by show post is \\n' + str(\n",
    "    avg_show_comments))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As shown, Ask posts category has a higher average number of comments (with ~14) than Show posts whose average number of comments is ~10.\n",
    "\n",
    "Therefore, we'll only analyze the Ask post category moving forward. We could analyze both categories, but to save time and because analyzing both may lead us to the same result as analyzing one with a higher average number of comments.\n",
    "\n",
    "\n",
    "\n",
    "## Average Number of Comments Received by Posts Each Hour\n",
    "\n",
    "The next point of action is to calculate the average number of comments that all sent posts got within each hour. In order to do this, we'll utilize the `created_at` and `num_comments` columns and assign both together in a dictionary. Each hour is going to serve as a dictionary key while the number of comments received will be the value for each key.\n",
    "\n",
    "At the end, we'll see each hour with its respective number of comments received and be able to calculate the average number of comments for each. The primary aim will be to determine the hour that has the highest average comments.\n",
    "\n",
    "We'll start by importing the datetime module in order to work with the time present in the `created_at` column and then extract both the number of comments and time together in the same list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing datetime function in order to work with date and time\n",
    "import datetime as dt\n",
    "\n",
    "num_com_time = []  # list for number of comment with the time post was created\n",
    "\n",
    "for posts in ask_posts:  # iterating over each posts in the lists\n",
    "    time_created = posts[-1]\n",
    "    num_comments = int(posts[4])\n",
    "    \n",
    "    # assigning the time each post was created \n",
    "    # and number of comments to the same variable\n",
    "    comment_n_time = time_created, num_comments\n",
    "    num_com_time.append(comment_n_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have succeeded in creating a list of lists that contains both the time and number of comments side by side."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'09': 45, '13': 85, '10': 59, '14': 107, '16': 108, '23': 68, '12': 73, '17': 100, '15': 116, '21': 109, '20': 80, '02': 58, '18': 109, '03': 54, '05': 46, '19': 110, '01': 60, '22': 71, '08': 48, '04': 47, '00': 55, '06': 44, '07': 34, '11': 58}\n",
      "\n",
      "\n",
      "{'09': 251, '13': 1253, '10': 793, '14': 1416, '16': 1814, '23': 543, '12': 687, '17': 1146, '15': 4477, '21': 1745, '20': 1722, '02': 1381, '18': 1439, '03': 421, '05': 464, '19': 1188, '01': 683, '22': 479, '08': 492, '04': 337, '00': 447, '06': 397, '07': 267, '11': 641}\n"
     ]
    }
   ],
   "source": [
    "counts_by_hour = {}    # dictionary for posts sent each hour\n",
    "comments_by_hour = {}  # dictionary for comments received by posts each hour\n",
    "\n",
    "\n",
    "for row in num_com_time:\n",
    "    date_n_time = row[0]\n",
    "    \n",
    "    # parsing the date and time format in the data set\n",
    "    date_n_time = dt.datetime.strptime(\n",
    "                 date_n_time, \"%m/%d/%Y %H:%M\")\n",
    "    hour_str = date_n_time.strftime(\"%H\")\n",
    "    \n",
    "    if hour_str not in counts_by_hour:\n",
    "        counts_by_hour[hour_str] = 1  # creating each element in the dictionary\n",
    "        comments_by_hour[hour_str] = row[1]  # # creating each element in the dictionary\n",
    "\n",
    "    else:\n",
    "        counts_by_hour[hour_str] += 1   # incrementing the elements in the dictionary\n",
    "        comments_by_hour[hour_str] += row[1]  # incrementing the elements in the dictionary\n",
    "print(counts_by_hour)\n",
    "print('\\n')\n",
    "print(comments_by_hour)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above, we created two dictionaries and displayed them:\n",
    "  \n",
    "  * `counts_by_hour`: contains the number of ask posts created during each hour of the day.\n",
    "  * `comments_by_hour`: contains the corresponding number of comments ask posts created at each hour received.\n",
    "  \n",
    "Right now, we'll use those two dictionaries to calculate the average number of comments for posts created during each hour of the day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['09', 5.5777777777777775], ['13', 14.741176470588234], ['10', 13.440677966101696], ['14', 13.233644859813085], ['16', 16.796296296296298], ['23', 7.985294117647059], ['12', 9.41095890410959], ['17', 11.46], ['15', 38.5948275862069], ['21', 16.009174311926607], ['20', 21.525], ['02', 23.810344827586206], ['18', 13.20183486238532], ['03', 7.796296296296297], ['05', 10.08695652173913], ['19', 10.8], ['01', 11.383333333333333], ['22', 6.746478873239437], ['08', 10.25], ['04', 7.170212765957447], ['00', 8.127272727272727], ['06', 9.022727272727273], ['07', 7.852941176470588], ['11', 11.051724137931034]]\n"
     ]
    }
   ],
   "source": [
    "avg_by_hour = []\n",
    "\n",
    "for hour in counts_by_hour:\n",
    "    avg_by_hour.append([hour,\n",
    "                        comments_by_hour[hour\n",
    "                                        ] / counts_by_hour[hour]])\n",
    "print(avg_by_hour)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the list up there, we can't at a glance identify which of the hours has the highest average value. For easy identification, we'll sort the list of lists from highest to lowest. We'll do that below and display the top five values. Since we're sorting based on the average values and not the hours, we'll first swap the hour (which is the first element of each row) with average value (which is the second element). \n",
    "\n",
    "At the end of this process, the average value will appear as the first element of the row while the hour will appear as the second element for each row. Afterwards we'll sort the list of lists in descending order (i.e. from highest to lowest)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5.5777777777777775, '09'], [14.741176470588234, '13'], [13.440677966101696, '10'], [13.233644859813085, '14'], [16.796296296296298, '16'], [7.985294117647059, '23'], [9.41095890410959, '12'], [11.46, '17'], [38.5948275862069, '15'], [16.009174311926607, '21'], [21.525, '20'], [23.810344827586206, '02'], [13.20183486238532, '18'], [7.796296296296297, '03'], [10.08695652173913, '05'], [10.8, '19'], [11.383333333333333, '01'], [6.746478873239437, '22'], [10.25, '08'], [7.170212765957447, '04'], [8.127272727272727, '00'], [9.022727272727273, '06'], [7.852941176470588, '07'], [11.051724137931034, '11']]\n"
     ]
    }
   ],
   "source": [
    "swap_avg_by_hour = []\n",
    "\n",
    "for row in avg_by_hour:\n",
    "    swap_avg_by_hour.append([row[1], row[0]])\n",
    "print(swap_avg_by_hour)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That is done! It appears pretty as well :). Now we can sort the list in descending order and display the top five hours accordingly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 Hours for Ask Posts Comments\n",
      "15:00: 38.59 average comments per posts\n",
      "02:00: 23.81 average comments per posts\n",
      "20:00: 21.52 average comments per posts\n",
      "16:00: 16.80 average comments per posts\n",
      "21:00: 16.01 average comments per posts\n"
     ]
    }
   ],
   "source": [
    "sorted_swap = sorted(swap_avg_by_hour, reverse=True)\n",
    "print( \"Top 5 Hours for Ask Posts Comments\")  # simply a title for our list\n",
    "\n",
    "hour_format = \"%H:%M\"    # the format we want the time to take\n",
    "for row in sorted_swap[:5]:\n",
    "    avg = row[0]\n",
    "    hour = str(row[1])   # converts the hours to string format\n",
    "    \n",
    "    hour = dt.datetime.strptime(hour, \"%H\")  # parses the hours as a datetime object\n",
    "    hour = hour.strftime(hour_format)        # specifies the format of the time\n",
    "    \n",
    "    # uses the format to print the hour and average\n",
    "    hour_avg_string = \"{h}: {a:.2f} average comments per posts\".format(h=hour, a=avg)\n",
    "    print(hour_avg_string)   # displays the top 5 hours according to the average comments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result is out! Posts sent within 15:00 (3PM) receives the most average comments per posts with a value of 38.59. Posts sent within 02:00 (2AM), 20:00 (8PM), 16:00 (4PM) and 21:00 (9PM) follows to make up the top five hours with the highest average comments per posts.\n",
    "\n",
    "Therefore, if an individual wants to ask anything and receive response to such a question he/she should endeavor to send them within those hours of the day. The time zone for our data set is the Eastern time in the US. Thus, individuals in other time zones should convert those times to their respective time zones.\n",
    "\n",
    "\n",
    "Let us see convert the top 5 hours to the a time zone an individual sending a post from Nigeria (timezone = Africa/Lagos) would have to send in his/her post to the platform:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20:00\n",
      "07:00\n",
      "01:00\n",
      "21:00\n",
      "02:00\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import pytz\n",
    "\n",
    "def convert_datetime_timezone(dt, tz1, tz2):\n",
    "    tz1 = pytz.timezone(tz1)  #  initial time zone\n",
    "    tz2 = pytz.timezone(tz2)  #  target time zone\n",
    "\n",
    "    dt = datetime.datetime.strptime(dt, \"%H\")\n",
    "    dt = tz1.localize(dt)\n",
    "    dt = dt.astimezone(tz2)\n",
    "    dt = dt.strftime(\"%H:00\")\n",
    "\n",
    "    return dt\n",
    "\n",
    "for row in sorted_swap[:5]:\n",
    "    hour = str(row[1])\n",
    "    nga_hours = convert_datetime_timezone(hour, \"US/Eastern\", \"Africa/Lagos\")\n",
    "    print(nga_hours)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Therefore, for a Nigerian posting on Hacker News platform, it would be advisable if he/she sends such post within the hours of 20:00 (8PM), 07:00 (7AM), 01:00 (1AM) etc. respectively.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "Our primary aim in this analysis was to determine the best time to send posts on the [Hacker News](https://news.ycombinator.com/) platform. This became necessary because most users become frustrated and disappointed when their questions go unanswered. We believe the understanding of a platform and the activity of its users is paramount to the attraction engagement/attention to a post.\n",
    "\n",
    "Therefore, we analyzed the average comments received by posts sent within each hour to determine the hours that has the most comment per post. In our result we found that: \n",
    "    \n",
    "   - [x] Ask posts (i.e. posts that come in form of questions) generally has more average number of comments more that Show posts. \n",
    "   - [x] Posts sent within the hour of 20:00 has the most engagement in form of comments. \n",
    "\n",
    "We can therefore suggest that users should send their posts within this hour in order for their posts to receive needed attention.\n",
    "\n",
    "#### Limitations\n",
    "\n",
    "In this analysis, we didn't:\n",
    "\n",
    "   - determine the hours the comments received by the posts were sent (this might be necessary to understand the time interval between the time the posts were created and the time the comments were received)\n",
    "   - determine the average number of points received by the posts.\n",
    "   \n",
    "   \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
